{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Sentiment Classification tasks with Llama-2-13B (HF, transformers) over WER-binned sample sentences",
   "id": "e590d6b77bb125a8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Setup",
   "id": "2a7189eac44d6f2d"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch\n",
    "from typing import List, Dict\n",
    "import logging\n",
    "logging.basicConfig(level = logging.INFO)"
   ],
   "id": "b1041afc14a75664"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###### Model Configuration",
   "id": "748469913234fd69"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model_id = \"meta-llama/Llama-2-13b-hf\"\n",
    "hf_token = os.environ.get(\"HF_TOKEN\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using:\", device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast = False, trust_remote_code = True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map = \"auto\",\n",
    "    trust_remote_code = True,\n",
    "    # TODO: consider quantization settings based on hardware\n",
    ")"
   ],
   "id": "348f3c42ea3ec1a9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###### Prompt Structure",
   "id": "23a2a834f6509405"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "ZERO_SHOT_PROMPT = \"\"\"\n",
    "<<SYS>>\n",
    "You are an assistant that classifies the sentiment of user utterances.  You must respond with three parts:\n",
    "1) A single label: `Positive`, `Negative`, or `Neutral`\n",
    "2) A short explanation (1–2 sentences) of why you chose that label\n",
    "3) (Optionally) any caveats or uncertainty if applicable\n",
    "<</SYS>>\n",
    "[INST]\n",
    "User: {sentence}\n",
    "[/INST]\n",
    "Assistant:\n",
    "\"\"\""
   ],
   "id": "4562ccbefdf823ce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# TODO: fill these manually\n",
    "FEW_SHOT_EXAMPLES = \"\"\"\n",
    "### EXAMPLES ###\n",
    "{examples}\n",
    "### END EXAMPLES ###\n",
    "\"\"\""
   ],
   "id": "a7d345cdf00d032b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "FEW_SHOT_PROMPT = \"\"\"\n",
    "<<SYS>>\n",
    "You are an assistant that classifies the sentiment of user utterances.  You must respond with three parts:\n",
    "1) A single label: `Positive`, `Negative`, or `Neutral`\n",
    "2) A short explanation (1–2 sentences) of why you chose that label\n",
    "3) (Optionally) any caveats or uncertainty if applicable\n",
    "<</SYS>>\n",
    "{examples}\n",
    "[INST]\n",
    "User: {sentence}\n",
    "[/INST]\n",
    "Assistant:\n",
    "\"\"\""
   ],
   "id": "11f725010bd8a2f0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Classify with Model",
   "id": "b6b05c6c4558c185"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###### Classify with Llama",
   "id": "10de2546a0f70c36"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# pass in a single sentence (either zero or few-shot) and return raw output from model\n",
    "# TODO: separate sentiment label and provided reason\n",
    "def classify_with_llama(sentence: str, few_shot: bool = False) -> str:\n",
    "    if few_shot:\n",
    "        prompt = FEW_SHOT_PROMPT.format(examples = FEW_SHOT_EXAMPLES, sentence = sentence)\n",
    "    else:\n",
    "        prompt = ZERO_SHOT_PROMPT.format(sentence = sentence)\n",
    "\n",
    "    outputs = gen_pipeline(\n",
    "        prompt,\n",
    "        max_new_tokens = 100,\n",
    "        do_sample = False,  # deterministic; you may try True for more variety\n",
    "        temperature = 0.0,  # consider increasing slightly\n",
    "        return_full_text = False,\n",
    "        eos_token_id = tokenizer.eos_token_id,\n",
    "    )\n",
    "\n",
    "    # outputs is a list of dicts, we take the first\n",
    "    text = outputs[0][\"generated_text\"].strip()\n",
    "    return text"
   ],
   "id": "512e78a758acca0a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# read inputs sentences from CSV containing sentences in a column headed with the value for inputs, returns DF with original + output\n",
    "def run_sentiment_on_csv(csv_path: str, inputs: str, few_shot: bool = False) -> pd.DataFrame:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    sentence_col = inputs\n",
    "\n",
    "    results = []\n",
    "    for _, row in df.iterrows():\n",
    "        sent = row[sentence_col]\n",
    "        try:\n",
    "            out = classify_with_llama(sent, few_shot = few_shot)\n",
    "        except Exception as e:\n",
    "            out = f\"ERROR: {e}\"\n",
    "        results.append(out)\n",
    "    df[\"llama_output\"] = results\n",
    "    return df"
   ],
   "id": "74f18fbb9bf0ce37"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Usage",
   "id": "850e4f37745b76bc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "save_directory = r\"data/model_outputs/llama_2_13b\"\n",
    "data_path = r\"data/reference\"\n",
    "input_files = []  # include \".csv\" in the path"
   ],
   "id": "c48f7d02972e42e9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###### Zero-shot",
   "id": "6a8dd22a8ceffdab"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# run zero-shot over all csv files in input_files\n",
    "zs_results = []\n",
    "for file in input_files:\n",
    "    print(\"Processing zero-shot on:\", file)\n",
    "    path = os.path.join(data_path, file)\n",
    "    classifications = run_sentiment_on_csv(path, \"Sentences\", few_shot = False)\n",
    "    zs_results.append(classifications)\n",
    "\n",
    "for file_name, classifications in zip(input_files, zs_results):\n",
    "    out_file = os.path.join(save_directory, file_name)\n",
    "    classifications.to_csv(out_file, index = False)"
   ],
   "id": "ac3e24c7a3e7aaf7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###### Few-shot",
   "id": "ec882521dc68d531"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "fs_results = []\n",
    "for file in input_files:\n",
    "    print(\"Processing few-shot on:\", file)\n",
    "    path = os.path.join(data_path, file)\n",
    "    classifications = run_sentiment_on_csv(path, \"Sentences\", few_shot = True)\n",
    "    fs_results.append(classifications)\n",
    "\n",
    "for file_name, classifications in zip(input_files, fs_results):\n",
    "    out_file = os.path.join(save_directory, file_name)\n",
    "    classifications.to_csv(out_file, index = False)"
   ],
   "id": "f6458548fd38c1c1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
