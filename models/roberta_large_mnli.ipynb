{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sentiment Classification tasks with RoBERTa Large MNLI (HF, transformers) over WER-binned sample sentences\n",
        "\n",
        "RoBERTa Large MNLI is RoBERTa fine-tuned on the Multi-Genre Natural Language Inference (MNLI) corpus - ideal for zero-shot classification.\n",
        "\n",
        "**Key Features:**\n",
        "- Model: [FacebookAI/roberta-large-mnli](https://huggingface.co/FacebookAI/roberta-large-mnli)\n",
        "- Parameters: ~355M (RoBERTa Large)\n",
        "- Training: Fine-tuned on MNLI (433k sentence pairs)\n",
        "- GLUE Score: 90.2% on MNLI\n",
        "- License: MIT\n",
        "- Approach: Zero-shot classification via Natural Language Inference\n",
        "\n",
        "**How it works:** Uses NLI to determine if text \"entails\" a sentiment label, enabling classification without task-specific fine-tuning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
        "import torch\n",
        "from typing import List, Dict\n",
        "import logging\n",
        "import random\n",
        "from datetime import datetime\n",
        "import re\n",
        "logging.basicConfig(level=logging.INFO)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###### Model Configuration\n",
        "\n",
        "RoBERTa Large MNLI is specifically trained for Natural Language Inference.\n",
        "It achieves 90.2% accuracy on the MNLI benchmark and is excellent for zero-shot classification.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RoBERTa Large fine-tuned on MNLI - excellent for zero-shot classification\n",
        "model_id = \"FacebookAI/roberta-large-mnli\"\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using:\", device)\n",
        "\n",
        "# Check GPU memory (if available)\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Total GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
        "\n",
        "# Initialize the zero-shot classification pipeline\n",
        "# RoBERTa MNLI is the go-to model for zero-shot classification\n",
        "zero_shot_pipeline = pipeline(\n",
        "    \"zero-shot-classification\",\n",
        "    model=model_id,\n",
        "    device=0 if torch.cuda.is_available() else -1\n",
        ")\n",
        "\n",
        "# Define sentiment labels for classification\n",
        "SENTIMENT_LABELS = [\"positive\", \"negative\", \"neutral\"]\n",
        "\n",
        "print(f\"✓ RoBERTa Large MNLI loaded successfully\")\n",
        "print(f\"  Model: {model_id}\")\n",
        "print(f\"  Parameters: ~355M\")\n",
        "print(f\"  MNLI Accuracy: 90.2%\")\n",
        "print(f\"  Candidate labels: {SENTIMENT_LABELS}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###### Test Pipeline (Optional - Run this to verify setup)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quick test to verify the pipeline works\n",
        "print(\"Testing RoBERTa MNLI zero-shot classification pipeline...\")\n",
        "\n",
        "test_sentences = [\n",
        "    \"I love this product, it's amazing!\",\n",
        "    \"This is terrible, I hate it.\",\n",
        "    \"The weather is okay today.\"\n",
        "]\n",
        "\n",
        "for sentence in test_sentences:\n",
        "    result = zero_shot_pipeline(sentence, SENTIMENT_LABELS)\n",
        "    top_label = result['labels'][0]\n",
        "    top_score = result['scores'][0]\n",
        "    print(f\"  '{sentence[:40]}...' -> {top_label} ({top_score:.4f})\")\n",
        "\n",
        "print(\"\\n✓ Test successful! RoBERTa MNLI is working correctly.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Loading and Processing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###### Load Data from XLSX\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_data_from_xlsx(xlsx_path: str, sheet_index: int = 1) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Load data from the second sheet (index 1) of an XLSX file.\n",
        "    Expected columns:\n",
        "    - Machine Transcription (ground truth)\n",
        "    - Human Transcription (hypothesis)\n",
        "    - Sentiment Label\n",
        "    - WER\n",
        "    - CER\n",
        "    - List of AAE features\n",
        "    - List of transcription errors\n",
        "    - Interview\n",
        "    \"\"\"\n",
        "    xl_file = pd.ExcelFile(xlsx_path)\n",
        "    sheet_names = xl_file.sheet_names\n",
        "    if len(sheet_names) <= sheet_index:\n",
        "        raise ValueError(f\"Sheet index {sheet_index} not available. Available sheets: {sheet_names}\")\n",
        "    \n",
        "    df = pd.read_excel(xlsx_path, sheet_name=sheet_index)\n",
        "    logging.info(f\"Loaded {len(df)} rows from sheet '{sheet_names[sheet_index]}'\")\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_data_into_sets(df: pd.DataFrame, test_ratio: float = 0.5, random_seed: int = None) -> tuple:\n",
        "    \"\"\"\n",
        "    Split dataframe into test and few-shot example sets.\n",
        "    Returns (test_df, few_shot_df) with equal sizes (or as close as possible).\n",
        "    \n",
        "    Note: For zero-shot classification, few-shot examples are not used.\n",
        "    This function is kept for API consistency with other model notebooks.\n",
        "    \"\"\"\n",
        "    if random_seed is not None:\n",
        "        random.seed(random_seed)\n",
        "    \n",
        "    # Shuffle the dataframe\n",
        "    df_shuffled = df.sample(frac=1, random_state=random_seed).reset_index(drop=True)\n",
        "    \n",
        "    # Split in half\n",
        "    split_idx = len(df_shuffled) // 2\n",
        "    test_df = df_shuffled.iloc[:split_idx].copy()\n",
        "    few_shot_df = df_shuffled.iloc[split_idx:].copy()\n",
        "    \n",
        "    logging.info(f\"Split data: {len(test_df)} test samples, {len(few_shot_df)} few-shot examples\")\n",
        "    return test_df, few_shot_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Classify with Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###### Zero-Shot Classification with RoBERTa MNLI\n",
        "\n",
        "**How NLI-based Zero-Shot Works:**\n",
        "1. For each candidate label, construct: \"This text is about [label]\"\n",
        "2. Use NLI to score if the text *entails* the hypothesis\n",
        "3. Return the label with highest entailment score\n",
        "\n",
        "RoBERTa MNLI achieves 90.2% on MNLI, making it one of the best models for this task.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def classify_with_roberta(sentence: str) -> tuple:\n",
        "    \"\"\"\n",
        "    Classify sentiment for a single sentence using RoBERTa MNLI zero-shot classification.\n",
        "    \n",
        "    RoBERTa MNLI uses Natural Language Inference to classify text into arbitrary labels\n",
        "    without requiring fine-tuning on sentiment data.\n",
        "    \n",
        "    Returns:\n",
        "        (raw_output, sentiment_label, reason)\n",
        "        - raw_output: String representation of classification results\n",
        "        - sentiment_label: Top predicted sentiment (Positive/Negative/Neutral)\n",
        "        - reason: Explanation based on confidence scores\n",
        "    \"\"\"\n",
        "    # Run zero-shot classification\n",
        "    with torch.no_grad():\n",
        "        result = zero_shot_pipeline(sentence, SENTIMENT_LABELS)\n",
        "    \n",
        "    # Get results\n",
        "    labels = result['labels']\n",
        "    scores = result['scores']\n",
        "    \n",
        "    top_label = labels[0].capitalize()\n",
        "    top_score = scores[0]\n",
        "    \n",
        "    # Build reason with all scores\n",
        "    score_details = \", \".join([f\"{l}: {s:.2%}\" for l, s in zip(labels, scores)])\n",
        "    reason = f\"RoBERTa MNLI scores: {score_details}\"\n",
        "    \n",
        "    # Format raw output for consistency with other models\n",
        "    raw_output = f\"[Top: {top_label} ({top_score:.4f}), All: {score_details}]\"\n",
        "    \n",
        "    return raw_output, top_label, reason\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Main Workflow\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###### Process All Samples\n",
        "\n",
        "RoBERTa MNLI performs zero-shot classification - no training data or few-shot examples needed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_all_samples(xlsx_path: str):\n",
        "    \"\"\"\n",
        "    Process ALL samples for sentiment analysis using RoBERTa MNLI.\n",
        "    \n",
        "    Args:\n",
        "        xlsx_path: Path to the XLSX file\n",
        "        \n",
        "    Returns:\n",
        "        DataFrame with results for all samples\n",
        "    \"\"\"\n",
        "    # Load data\n",
        "    df = load_data_from_xlsx(xlsx_path, sheet_index=1)\n",
        "    \n",
        "    logging.info(f\"Processing all {len(df)} samples with RoBERTa MNLI\")\n",
        "    \n",
        "    # Prepare results list\n",
        "    results = []\n",
        "    \n",
        "    # Process each sample\n",
        "    for idx, (_, row) in enumerate(df.iterrows(), 1):\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"Processing sentence {idx}/{len(df)}\")\n",
        "        print(f\"{'='*80}\")\n",
        "        \n",
        "        # Get column names\n",
        "        machine_col = None\n",
        "        human_col = None\n",
        "        \n",
        "        for col in row.index:\n",
        "            if 'machine' in col.lower() and 'transcription' in col.lower():\n",
        "                machine_col = col\n",
        "            elif 'human' in col.lower() and 'transcription' in col.lower():\n",
        "                human_col = col\n",
        "        \n",
        "        if machine_col is None or human_col is None:\n",
        "            # Fallback to first two columns\n",
        "            cols = list(row.index)\n",
        "            machine_col = cols[0] if machine_col is None else machine_col\n",
        "            human_col = cols[1] if human_col is None else human_col\n",
        "        \n",
        "        ground_truth = row.get(machine_col, \"\")\n",
        "        hypothesis = row.get(human_col, \"\")\n",
        "        \n",
        "        print(f\"\\nGround Truth: {ground_truth}\")\n",
        "        print(f\"Hypothesis: {hypothesis}\")\n",
        "        \n",
        "        # Classify\n",
        "        try:\n",
        "            raw_output, sentiment_label, reason = classify_with_roberta(hypothesis)\n",
        "            \n",
        "            print(f\"\\nModel Output: {raw_output}\")\n",
        "            print(f\"Parsed Sentiment: {sentiment_label}\")\n",
        "            print(f\"Reason: {reason}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"\\nERROR: {e}\")\n",
        "            raw_output = f\"ERROR: {e}\"\n",
        "            sentiment_label = \"ERROR\"\n",
        "            reason = str(e)\n",
        "        \n",
        "        # Store results\n",
        "        results.append({\n",
        "            'ground_truth': ground_truth,\n",
        "            'hypothesis': hypothesis,\n",
        "            'sentiment_label': sentiment_label,\n",
        "            'reason': reason\n",
        "        })\n",
        "    \n",
        "    # Create results dataframe\n",
        "    results_df = pd.DataFrame(results)\n",
        "    \n",
        "    # Save to CSV\n",
        "    today = datetime.now().strftime(\"%Y%m%d\")\n",
        "    output_filename = f\"roberta_large_mnli_all_samples_{today}.csv\"\n",
        "    \n",
        "    # Create output directory if it doesn't exist\n",
        "    output_dir = r\"data/model_outputs/roberta_large_mnli\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    \n",
        "    output_path = os.path.join(output_dir, output_filename)\n",
        "    results_df.to_csv(output_path, index=False)\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"Results saved to: {output_path}\")\n",
        "    print(f\"Total samples processed: {len(results_df)}\")\n",
        "    print(f\"{'='*80}\")\n",
        "    \n",
        "    return results_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_sentiment_analysis(xlsx_path: str, few_shot: bool = False, random_seed: int = 42):\n",
        "    \"\"\"\n",
        "    Process sentiment analysis with optional data splitting.\n",
        "    \n",
        "    Note: The few_shot parameter is kept for API consistency with other model notebooks,\n",
        "    but zero-shot classification doesn't use few-shot examples.\n",
        "    \n",
        "    Args:\n",
        "        xlsx_path: Path to the XLSX file\n",
        "        few_shot: Ignored for zero-shot classification (kept for API consistency)\n",
        "        random_seed: Random seed for data splitting\n",
        "        \n",
        "    Returns:\n",
        "        DataFrame with results\n",
        "    \"\"\"\n",
        "    # Load data\n",
        "    df = load_data_from_xlsx(xlsx_path, sheet_index=1)\n",
        "    \n",
        "    # Split data (for consistency, even though zero-shot doesn't use few-shot)\n",
        "    test_df, _ = split_data_into_sets(df, test_ratio=0.5, random_seed=random_seed)\n",
        "    \n",
        "    logging.info(f\"Processing {len(test_df)} samples with RoBERTa MNLI (split mode)\")\n",
        "    \n",
        "    # Prepare results list\n",
        "    results = []\n",
        "    \n",
        "    # Process each test sentence\n",
        "    for idx, (_, row) in enumerate(test_df.iterrows(), 1):\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"Processing sentence {idx}/{len(test_df)}\")\n",
        "        print(f\"{'='*80}\")\n",
        "        \n",
        "        # Get column names\n",
        "        machine_col = None\n",
        "        human_col = None\n",
        "        \n",
        "        for col in row.index:\n",
        "            if 'machine' in col.lower() and 'transcription' in col.lower():\n",
        "                machine_col = col\n",
        "            elif 'human' in col.lower() and 'transcription' in col.lower():\n",
        "                human_col = col\n",
        "        \n",
        "        if machine_col is None or human_col is None:\n",
        "            # Fallback to first two columns\n",
        "            cols = list(row.index)\n",
        "            machine_col = cols[0] if machine_col is None else machine_col\n",
        "            human_col = cols[1] if human_col is None else human_col\n",
        "        \n",
        "        ground_truth = row.get(machine_col, \"\")\n",
        "        hypothesis = row.get(human_col, \"\")\n",
        "        \n",
        "        print(f\"\\nGround Truth: {ground_truth}\")\n",
        "        print(f\"Hypothesis: {hypothesis}\")\n",
        "        \n",
        "        # Classify\n",
        "        try:\n",
        "            raw_output, sentiment_label, reason = classify_with_roberta(hypothesis)\n",
        "            \n",
        "            print(f\"\\nModel Output: {raw_output}\")\n",
        "            print(f\"Parsed Sentiment: {sentiment_label}\")\n",
        "            print(f\"Reason: {reason}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"\\nERROR: {e}\")\n",
        "            raw_output = f\"ERROR: {e}\"\n",
        "            sentiment_label = \"ERROR\"\n",
        "            reason = str(e)\n",
        "        \n",
        "        # Store results\n",
        "        results.append({\n",
        "            'ground_truth': ground_truth,\n",
        "            'hypothesis': hypothesis,\n",
        "            'sentiment_label': sentiment_label,\n",
        "            'reason': reason\n",
        "        })\n",
        "    \n",
        "    # Create results dataframe\n",
        "    results_df = pd.DataFrame(results)\n",
        "    \n",
        "    # Save to CSV\n",
        "    today = datetime.now().strftime(\"%Y%m%d\")\n",
        "    output_filename = f\"roberta_large_mnli_split_{today}.csv\"\n",
        "    \n",
        "    # Create output directory if it doesn't exist\n",
        "    output_dir = r\"data/model_outputs/roberta_large_mnli\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    \n",
        "    output_path = os.path.join(output_dir, output_filename)\n",
        "    results_df.to_csv(output_path, index=False)\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"Results saved to: {output_path}\")\n",
        "    print(f\"{'='*80}\")\n",
        "    \n",
        "    return results_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Batch Processing (Faster)\n",
        "\n",
        "RoBERTa MNLI supports batch processing for improved throughput.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_all_samples_batch(xlsx_path: str, batch_size: int = 8):\n",
        "    \"\"\"\n",
        "    Process ALL samples using batch processing for faster inference.\n",
        "    \n",
        "    Note: Zero-shot classification requires NLI inference for each label,\n",
        "    so batch size should be smaller than direct classification models.\n",
        "    \n",
        "    Args:\n",
        "        xlsx_path: Path to the XLSX file\n",
        "        batch_size: Number of sentences to process at once\n",
        "        \n",
        "    Returns:\n",
        "        DataFrame with results for all samples\n",
        "    \"\"\"\n",
        "    # Load data\n",
        "    df = load_data_from_xlsx(xlsx_path, sheet_index=1)\n",
        "    \n",
        "    logging.info(f\"Processing all {len(df)} samples with RoBERTa MNLI (batch mode, batch_size={batch_size})\")\n",
        "    \n",
        "    # Get column names from first row\n",
        "    sample_row = df.iloc[0]\n",
        "    machine_col = None\n",
        "    human_col = None\n",
        "    \n",
        "    for col in sample_row.index:\n",
        "        if 'machine' in col.lower() and 'transcription' in col.lower():\n",
        "            machine_col = col\n",
        "        elif 'human' in col.lower() and 'transcription' in col.lower():\n",
        "            human_col = col\n",
        "    \n",
        "    if machine_col is None or human_col is None:\n",
        "        cols = list(sample_row.index)\n",
        "        machine_col = cols[0] if machine_col is None else machine_col\n",
        "        human_col = cols[1] if human_col is None else human_col\n",
        "    \n",
        "    # Extract sentences\n",
        "    ground_truths = df[machine_col].tolist()\n",
        "    hypotheses = df[human_col].tolist()\n",
        "    \n",
        "    # Process in batches\n",
        "    print(f\"Processing {len(hypotheses)} sentences in batches of {batch_size}...\")\n",
        "    \n",
        "    all_results = []\n",
        "    for i in range(0, len(hypotheses), batch_size):\n",
        "        batch = hypotheses[i:i+batch_size]\n",
        "        # Zero-shot pipeline can handle lists\n",
        "        batch_results = zero_shot_pipeline(batch, SENTIMENT_LABELS)\n",
        "        # Handle single item vs list return\n",
        "        if not isinstance(batch_results, list):\n",
        "            batch_results = [batch_results]\n",
        "        all_results.extend(batch_results)\n",
        "        print(f\"  Processed {min(i+batch_size, len(hypotheses))}/{len(hypotheses)} sentences\")\n",
        "    \n",
        "    # Build results dataframe\n",
        "    results = []\n",
        "    for idx, (gt, hyp, res) in enumerate(zip(ground_truths, hypotheses, all_results)):\n",
        "        top_label = res['labels'][0].capitalize()\n",
        "        scores = res['scores']\n",
        "        labels = res['labels']\n",
        "        \n",
        "        score_details = \", \".join([f\"{l}: {s:.2%}\" for l, s in zip(labels, scores)])\n",
        "        reason = f\"RoBERTa MNLI scores: {score_details}\"\n",
        "        \n",
        "        results.append({\n",
        "            'ground_truth': gt,\n",
        "            'hypothesis': hyp,\n",
        "            'sentiment_label': top_label,\n",
        "            'reason': reason\n",
        "        })\n",
        "    \n",
        "    results_df = pd.DataFrame(results)\n",
        "    \n",
        "    # Save to CSV\n",
        "    today = datetime.now().strftime(\"%Y%m%d\")\n",
        "    output_filename = f\"roberta_large_mnli_batch_all_samples_{today}.csv\"\n",
        "    \n",
        "    output_dir = r\"data/model_outputs/roberta_large_mnli\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    \n",
        "    output_path = os.path.join(output_dir, output_filename)\n",
        "    results_df.to_csv(output_path, index=False)\n",
        "    \n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"Results saved to: {output_path}\")\n",
        "    print(f\"Total samples processed: {len(results_df)}\")\n",
        "    print(f\"{'='*80}\")\n",
        "    \n",
        "    return results_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Usage\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Specify the path to your XLSX file\n",
        "xlsx_file_path = r\"C:\\Users\\pryce\\OneDrive\\Desktop\\Lost in Transcription\\Text Inputs\\Samples.xlsx\"  # Update this path\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "RANDOM_SEED = 33\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###### Option 1: Process with Split (50% of data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run sentiment analysis on 50% of data (split mode)\n",
        "split_results = process_sentiment_analysis(\n",
        "    xlsx_file_path, \n",
        "    random_seed=RANDOM_SEED\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###### Option 2: Process All Samples (One by One)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run sentiment analysis on ALL samples (verbose, one by one)\n",
        "all_results = process_all_samples(xlsx_file_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###### Option 3: Batch Processing (Faster)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run sentiment analysis on ALL samples using batch processing\n",
        "# batch_size=8 is recommended for zero-shot classification\n",
        "batch_results = process_all_samples_batch(xlsx_file_path, batch_size=8)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
