{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sentiment Classification tasks with DistilBERT (HF, transformers) over WER-binned sample sentences\n",
        "\n",
        "DistilBERT is a smaller, faster, cheaper version of BERT that retains 97% of its language understanding capabilities.\n",
        "\n",
        "**Important:** Unlike the generative models (Llama, Vicuna, Mistral), DistilBERT is an **encoder-only model** that doesn't generate text. Instead, it classifies input directly.\n",
        "\n",
        "- Base Model: [distilbert/distilbert-base-uncased](https://huggingface.co/distilbert/distilbert-base-uncased)\n",
        "- Sentiment Model: [distilbert-base-uncased-finetuned-sst-2-english](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n",
        "- Parameters: 67M (much smaller than 13B-22B generative models)\n",
        "- License: Apache 2.0\n",
        "- Output: Direct classification labels (POSITIVE/NEGATIVE) with confidence scores\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
        "import torch\n",
        "from typing import List, Dict\n",
        "import logging\n",
        "import random\n",
        "from datetime import datetime\n",
        "import re\n",
        "logging.basicConfig(level=logging.INFO)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###### Model Configuration\n",
        "\n",
        "DistilBERT is very lightweight (67M parameters) and runs efficiently on CPU or GPU.\n",
        "No quantization needed - the model is small enough to run on most hardware.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Using the sentiment-fine-tuned version of DistilBERT\n",
        "# The base model (distilbert-base-uncased) is for feature extraction/fine-tuning\n",
        "# This fine-tuned version is ready for sentiment classification\n",
        "model_id = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using:\", device)\n",
        "\n",
        "# Check GPU memory (if available)\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Total GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
        "\n",
        "# Load tokenizer and model for sequence classification\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_id)\n",
        "\n",
        "# Move model to device\n",
        "model = model.to(device)\n",
        "\n",
        "# Initialize the sentiment analysis pipeline\n",
        "# DistilBERT uses \"sentiment-analysis\" or \"text-classification\" pipeline (NOT text-generation)\n",
        "sentiment_pipeline = pipeline(\n",
        "    \"sentiment-analysis\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=0 if torch.cuda.is_available() else -1\n",
        ")\n",
        "\n",
        "print(f\"✓ DistilBERT sentiment model loaded successfully\")\n",
        "print(f\"  Model size: ~67M parameters\")\n",
        "print(f\"  Output labels: POSITIVE, NEGATIVE\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###### Test Pipeline (Optional - Run this to verify setup)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quick test to verify the pipeline works\n",
        "# DistilBERT is fast - this should complete almost instantly\n",
        "print(\"Testing DistilBERT sentiment pipeline...\")\n",
        "\n",
        "test_sentences = [\n",
        "    \"I love this product, it's amazing!\",\n",
        "    \"This is terrible, I hate it.\",\n",
        "    \"The weather is okay today.\"\n",
        "]\n",
        "\n",
        "for sentence in test_sentences:\n",
        "    result = sentiment_pipeline(sentence)[0]\n",
        "    print(f\"  '{sentence[:40]}...' -> {result['label']} ({result['score']:.4f})\")\n",
        "\n",
        "print(\"\\n✓ Test successful! DistilBERT is working correctly.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Loading and Processing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###### Load Data from XLSX\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_data_from_xlsx(xlsx_path: str, sheet_index: int = 1) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Load data from the second sheet (index 1) of an XLSX file.\n",
        "    Expected columns:\n",
        "    - Machine Transcription (ground truth)\n",
        "    - Human Transcription (hypothesis)\n",
        "    - Sentiment Label\n",
        "    - WER\n",
        "    - CER\n",
        "    - List of AAE features\n",
        "    - List of transcription errors\n",
        "    - Interview\n",
        "    \"\"\"\n",
        "    xl_file = pd.ExcelFile(xlsx_path)\n",
        "    sheet_names = xl_file.sheet_names\n",
        "    if len(sheet_names) <= sheet_index:\n",
        "        raise ValueError(f\"Sheet index {sheet_index} not available. Available sheets: {sheet_names}\")\n",
        "    \n",
        "    df = pd.read_excel(xlsx_path, sheet_name=sheet_index)\n",
        "    logging.info(f\"Loaded {len(df)} rows from sheet '{sheet_names[sheet_index]}'\")\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_data_into_sets(df: pd.DataFrame, test_ratio: float = 0.5, random_seed: int = None) -> tuple:\n",
        "    \"\"\"\n",
        "    Split dataframe into test and few-shot example sets.\n",
        "    Returns (test_df, few_shot_df) with equal sizes (or as close as possible).\n",
        "    \n",
        "    Note: For DistilBERT, few-shot examples are not used (model is pre-trained for classification).\n",
        "    This function is kept for API consistency with other model notebooks.\n",
        "    \"\"\"\n",
        "    if random_seed is not None:\n",
        "        random.seed(random_seed)\n",
        "    \n",
        "    # Shuffle the dataframe\n",
        "    df_shuffled = df.sample(frac=1, random_state=random_seed).reset_index(drop=True)\n",
        "    \n",
        "    # Split in half\n",
        "    split_idx = len(df_shuffled) // 2\n",
        "    test_df = df_shuffled.iloc[:split_idx].copy()\n",
        "    few_shot_df = df_shuffled.iloc[split_idx:].copy()\n",
        "    \n",
        "    logging.info(f\"Split data: {len(test_df)} test samples, {len(few_shot_df)} few-shot examples\")\n",
        "    return test_df, few_shot_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Classify with Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###### Classify with DistilBERT\n",
        "\n",
        "**Key Difference:** DistilBERT doesn't use prompts or generate text. It directly classifies the input and returns:\n",
        "- `label`: POSITIVE or NEGATIVE\n",
        "- `score`: confidence score (0-1)\n",
        "\n",
        "Note: The SST-2 fine-tuned model only outputs POSITIVE/NEGATIVE (binary classification).\n",
        "NEUTRAL is approximated based on low confidence scores.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def map_distilbert_to_sentiment(label: str, score: float, neutral_threshold: float = 0.6) -> str:\n",
        "    \"\"\"\n",
        "    Map DistilBERT's binary output (POSITIVE/NEGATIVE) to our three-class system.\n",
        "    \n",
        "    If the confidence score is below the threshold, classify as NEUTRAL.\n",
        "    This approximates neutral sentiment for borderline cases.\n",
        "    \n",
        "    Args:\n",
        "        label: DistilBERT output label (POSITIVE or NEGATIVE)\n",
        "        score: Confidence score (0-1)\n",
        "        neutral_threshold: Below this confidence, classify as NEUTRAL\n",
        "        \n",
        "    Returns:\n",
        "        Mapped sentiment label: Positive, Negative, or Neutral\n",
        "    \"\"\"\n",
        "    if score < neutral_threshold:\n",
        "        return \"Neutral\"\n",
        "    elif label == \"POSITIVE\":\n",
        "        return \"Positive\"\n",
        "    else:\n",
        "        return \"Negative\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def classify_with_distilbert(sentence: str) -> tuple:\n",
        "    \"\"\"\n",
        "    Classify sentiment for a single sentence using DistilBERT.\n",
        "    \n",
        "    Unlike generative models, DistilBERT:\n",
        "    - Doesn't use prompts\n",
        "    - Doesn't generate text\n",
        "    - Returns classification directly\n",
        "    \n",
        "    Returns:\n",
        "        (raw_output, sentiment_label, reason)\n",
        "        - raw_output: Dictionary with label and score\n",
        "        - sentiment_label: Mapped sentiment (Positive/Negative/Neutral)\n",
        "        - reason: Explanation based on confidence score\n",
        "    \"\"\"\n",
        "    # Run classification\n",
        "    with torch.no_grad():\n",
        "        result = sentiment_pipeline(sentence)[0]\n",
        "    \n",
        "    label = result['label']\n",
        "    score = result['score']\n",
        "    \n",
        "    # Map to three-class sentiment\n",
        "    sentiment_label = map_distilbert_to_sentiment(label, score)\n",
        "    \n",
        "    # Generate a reason based on the classification\n",
        "    if sentiment_label == \"Neutral\":\n",
        "        reason = f\"Low confidence ({score:.2%}) suggests ambiguous sentiment\"\n",
        "    else:\n",
        "        reason = f\"Classified as {label} with {score:.2%} confidence\"\n",
        "    \n",
        "    # Format raw output as string for consistency with other models\n",
        "    raw_output = f\"[Label: {label}, Score: {score:.4f}]\"\n",
        "    \n",
        "    return raw_output, sentiment_label, reason\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Main Workflow\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###### Process All Samples\n",
        "\n",
        "Note: DistilBERT doesn't support few-shot learning (it's a fine-tuned classification model).\n",
        "All processing is effectively \"zero-shot\" - the model classifies directly based on its training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_all_samples(xlsx_path: str):\n",
        "    \"\"\"\n",
        "    Process ALL samples for sentiment analysis.\n",
        "    \n",
        "    DistilBERT processes all samples the same way (no few-shot/zero-shot distinction).\n",
        "    This is much faster than generative models due to:\n",
        "    - Smaller model size (67M vs 13B+ parameters)\n",
        "    - Direct classification (no text generation)\n",
        "    - Batch processing capability\n",
        "    \n",
        "    Args:\n",
        "        xlsx_path: Path to the XLSX file\n",
        "        \n",
        "    Returns:\n",
        "        DataFrame with results for all samples\n",
        "    \"\"\"\n",
        "    # Load data\n",
        "    df = load_data_from_xlsx(xlsx_path, sheet_index=1)\n",
        "    \n",
        "    logging.info(f\"Processing all {len(df)} samples with DistilBERT\")\n",
        "    \n",
        "    # Prepare results list\n",
        "    results = []\n",
        "    \n",
        "    # Process each sample\n",
        "    for idx, (_, row) in enumerate(df.iterrows(), 1):\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"Processing sentence {idx}/{len(df)}\")\n",
        "        print(f\"{'='*80}\")\n",
        "        \n",
        "        # Get column names\n",
        "        machine_col = None\n",
        "        human_col = None\n",
        "        \n",
        "        for col in row.index:\n",
        "            if 'machine' in col.lower() and 'transcription' in col.lower():\n",
        "                machine_col = col\n",
        "            elif 'human' in col.lower() and 'transcription' in col.lower():\n",
        "                human_col = col\n",
        "        \n",
        "        if machine_col is None or human_col is None:\n",
        "            # Fallback to first two columns\n",
        "            cols = list(row.index)\n",
        "            machine_col = cols[0] if machine_col is None else machine_col\n",
        "            human_col = cols[1] if human_col is None else human_col\n",
        "        \n",
        "        ground_truth = row.get(machine_col, \"\")\n",
        "        hypothesis = row.get(human_col, \"\")\n",
        "        \n",
        "        print(f\"\\nGround Truth: {ground_truth}\")\n",
        "        print(f\"Hypothesis: {hypothesis}\")\n",
        "        \n",
        "        # Classify (no prompt needed for DistilBERT)\n",
        "        try:\n",
        "            raw_output, sentiment_label, reason = classify_with_distilbert(hypothesis)\n",
        "            \n",
        "            print(f\"\\nModel Output: {raw_output}\")\n",
        "            print(f\"Parsed Sentiment: {sentiment_label}\")\n",
        "            print(f\"Reason: {reason}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"\\nERROR: {e}\")\n",
        "            raw_output = f\"ERROR: {e}\"\n",
        "            sentiment_label = \"ERROR\"\n",
        "            reason = str(e)\n",
        "        \n",
        "        # Store results\n",
        "        results.append({\n",
        "            'ground_truth': ground_truth,\n",
        "            'hypothesis': hypothesis,\n",
        "            'sentiment_label': sentiment_label,\n",
        "            'reason': reason\n",
        "        })\n",
        "    \n",
        "    # Create results dataframe\n",
        "    results_df = pd.DataFrame(results)\n",
        "    \n",
        "    # Save to CSV\n",
        "    today = datetime.now().strftime(\"%Y%m%d\")\n",
        "    output_filename = f\"distilbert_base_uncased_all_samples_{today}.csv\"\n",
        "    \n",
        "    # Create output directory if it doesn't exist\n",
        "    output_dir = r\"data/model_outputs/distilbert_base_uncased\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    \n",
        "    output_path = os.path.join(output_dir, output_filename)\n",
        "    results_df.to_csv(output_path, index=False)\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"Results saved to: {output_path}\")\n",
        "    print(f\"Total samples processed: {len(results_df)}\")\n",
        "    print(f\"{'='*80}\")\n",
        "    \n",
        "    return results_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_sentiment_analysis(xlsx_path: str, few_shot: bool = False, random_seed: int = 42):\n",
        "    \"\"\"\n",
        "    Process sentiment analysis with optional data splitting.\n",
        "    \n",
        "    Note: The few_shot parameter is kept for API consistency with other model notebooks,\n",
        "    but DistilBERT doesn't actually use few-shot examples - it's a pre-trained classifier.\n",
        "    \n",
        "    Args:\n",
        "        xlsx_path: Path to the XLSX file\n",
        "        few_shot: Ignored for DistilBERT (kept for API consistency)\n",
        "        random_seed: Random seed for data splitting\n",
        "        \n",
        "    Returns:\n",
        "        DataFrame with results\n",
        "    \"\"\"\n",
        "    # Load data\n",
        "    df = load_data_from_xlsx(xlsx_path, sheet_index=1)\n",
        "    \n",
        "    # Split data (for consistency, even though DistilBERT doesn't use few-shot)\n",
        "    test_df, _ = split_data_into_sets(df, test_ratio=0.5, random_seed=random_seed)\n",
        "    \n",
        "    logging.info(f\"Processing {len(test_df)} samples with DistilBERT (split mode)\")\n",
        "    \n",
        "    # Prepare results list\n",
        "    results = []\n",
        "    \n",
        "    # Process each test sentence\n",
        "    for idx, (_, row) in enumerate(test_df.iterrows(), 1):\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"Processing sentence {idx}/{len(test_df)}\")\n",
        "        print(f\"{'='*80}\")\n",
        "        \n",
        "        # Get column names\n",
        "        machine_col = None\n",
        "        human_col = None\n",
        "        \n",
        "        for col in row.index:\n",
        "            if 'machine' in col.lower() and 'transcription' in col.lower():\n",
        "                machine_col = col\n",
        "            elif 'human' in col.lower() and 'transcription' in col.lower():\n",
        "                human_col = col\n",
        "        \n",
        "        if machine_col is None or human_col is None:\n",
        "            # Fallback to first two columns\n",
        "            cols = list(row.index)\n",
        "            machine_col = cols[0] if machine_col is None else machine_col\n",
        "            human_col = cols[1] if human_col is None else human_col\n",
        "        \n",
        "        ground_truth = row.get(machine_col, \"\")\n",
        "        hypothesis = row.get(human_col, \"\")\n",
        "        \n",
        "        print(f\"\\nGround Truth: {ground_truth}\")\n",
        "        print(f\"Hypothesis: {hypothesis}\")\n",
        "        \n",
        "        # Classify\n",
        "        try:\n",
        "            raw_output, sentiment_label, reason = classify_with_distilbert(hypothesis)\n",
        "            \n",
        "            print(f\"\\nModel Output: {raw_output}\")\n",
        "            print(f\"Parsed Sentiment: {sentiment_label}\")\n",
        "            print(f\"Reason: {reason}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"\\nERROR: {e}\")\n",
        "            raw_output = f\"ERROR: {e}\"\n",
        "            sentiment_label = \"ERROR\"\n",
        "            reason = str(e)\n",
        "        \n",
        "        # Store results\n",
        "        results.append({\n",
        "            'ground_truth': ground_truth,\n",
        "            'hypothesis': hypothesis,\n",
        "            'sentiment_label': sentiment_label,\n",
        "            'reason': reason\n",
        "        })\n",
        "    \n",
        "    # Create results dataframe\n",
        "    results_df = pd.DataFrame(results)\n",
        "    \n",
        "    # Save to CSV\n",
        "    today = datetime.now().strftime(\"%Y%m%d\")\n",
        "    output_filename = f\"distilbert_base_uncased_split_{today}.csv\"\n",
        "    \n",
        "    # Create output directory if it doesn't exist\n",
        "    output_dir = r\"data/model_outputs/distilbert_base_uncased\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    \n",
        "    output_path = os.path.join(output_dir, output_filename)\n",
        "    results_df.to_csv(output_path, index=False)\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"Results saved to: {output_path}\")\n",
        "    print(f\"{'='*80}\")\n",
        "    \n",
        "    return results_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Batch Processing (Faster)\n",
        "\n",
        "DistilBERT supports efficient batch processing, which is much faster than processing one sentence at a time.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_all_samples_batch(xlsx_path: str, batch_size: int = 32):\n",
        "    \"\"\"\n",
        "    Process ALL samples using batch processing for faster inference.\n",
        "    \n",
        "    This is the recommended approach for DistilBERT as it's much faster\n",
        "    than processing one sentence at a time.\n",
        "    \n",
        "    Args:\n",
        "        xlsx_path: Path to the XLSX file\n",
        "        batch_size: Number of sentences to process at once\n",
        "        \n",
        "    Returns:\n",
        "        DataFrame with results for all samples\n",
        "    \"\"\"\n",
        "    # Load data\n",
        "    df = load_data_from_xlsx(xlsx_path, sheet_index=1)\n",
        "    \n",
        "    logging.info(f\"Processing all {len(df)} samples with DistilBERT (batch mode, batch_size={batch_size})\")\n",
        "    \n",
        "    # Get column names from first row\n",
        "    sample_row = df.iloc[0]\n",
        "    machine_col = None\n",
        "    human_col = None\n",
        "    \n",
        "    for col in sample_row.index:\n",
        "        if 'machine' in col.lower() and 'transcription' in col.lower():\n",
        "            machine_col = col\n",
        "        elif 'human' in col.lower() and 'transcription' in col.lower():\n",
        "            human_col = col\n",
        "    \n",
        "    if machine_col is None or human_col is None:\n",
        "        cols = list(sample_row.index)\n",
        "        machine_col = cols[0] if machine_col is None else machine_col\n",
        "        human_col = cols[1] if human_col is None else human_col\n",
        "    \n",
        "    # Extract sentences\n",
        "    ground_truths = df[machine_col].tolist()\n",
        "    hypotheses = df[human_col].tolist()\n",
        "    \n",
        "    # Process in batches\n",
        "    print(f\"Processing {len(hypotheses)} sentences in batches of {batch_size}...\")\n",
        "    \n",
        "    all_results = []\n",
        "    for i in range(0, len(hypotheses), batch_size):\n",
        "        batch = hypotheses[i:i+batch_size]\n",
        "        batch_results = sentiment_pipeline(batch)\n",
        "        all_results.extend(batch_results)\n",
        "        print(f\"  Processed {min(i+batch_size, len(hypotheses))}/{len(hypotheses)} sentences\")\n",
        "    \n",
        "    # Build results dataframe\n",
        "    results = []\n",
        "    for idx, (gt, hyp, res) in enumerate(zip(ground_truths, hypotheses, all_results)):\n",
        "        sentiment_label = map_distilbert_to_sentiment(res['label'], res['score'])\n",
        "        \n",
        "        if sentiment_label == \"Neutral\":\n",
        "            reason = f\"Low confidence ({res['score']:.2%}) suggests ambiguous sentiment\"\n",
        "        else:\n",
        "            reason = f\"Classified as {res['label']} with {res['score']:.2%} confidence\"\n",
        "        \n",
        "        results.append({\n",
        "            'ground_truth': gt,\n",
        "            'hypothesis': hyp,\n",
        "            'sentiment_label': sentiment_label,\n",
        "            'reason': reason\n",
        "        })\n",
        "    \n",
        "    results_df = pd.DataFrame(results)\n",
        "    \n",
        "    # Save to CSV\n",
        "    today = datetime.now().strftime(\"%Y%m%d\")\n",
        "    output_filename = f\"distilbert_base_uncased_batch_all_samples_{today}.csv\"\n",
        "    \n",
        "    output_dir = r\"data/model_outputs/distilbert_base_uncased\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    \n",
        "    output_path = os.path.join(output_dir, output_filename)\n",
        "    results_df.to_csv(output_path, index=False)\n",
        "    \n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"Results saved to: {output_path}\")\n",
        "    print(f\"Total samples processed: {len(results_df)}\")\n",
        "    print(f\"{'='*80}\")\n",
        "    \n",
        "    return results_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Usage\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Specify the path to your XLSX file\n",
        "xlsx_file_path = r\"C:\\Users\\pryce\\OneDrive\\Desktop\\Lost in Transcription\\Text Inputs\\Samples.xlsx\"  # Update this path\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "RANDOM_SEED = 33\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###### Option 1: Process with Split (50% of data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run sentiment analysis on 50% of data (split mode)\n",
        "split_results = process_sentiment_analysis(\n",
        "    xlsx_file_path, \n",
        "    random_seed=RANDOM_SEED\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###### Option 2: Process All Samples (One by One)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run sentiment analysis on ALL samples (verbose, one by one)\n",
        "all_results = process_all_samples(xlsx_file_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###### Option 3: Batch Processing (Recommended - Fastest)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run sentiment analysis on ALL samples using batch processing (fastest)\n",
        "batch_results = process_all_samples_batch(xlsx_file_path, batch_size=32)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
